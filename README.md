# üìä DataDock

**Sistema completo de gerenciamento e importa√ß√£o de dados com suporte a m√∫ltiplas fontes**

[![Django](https://img.shields.io/badge/Django-5.2-green.svg)](https://www.djangoproject.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15-black.svg)](https://nextjs.org/)
[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue.svg)](https://www.typescriptlang.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

---

## üìë √çndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [Funcionalidades](#-funcionalidades)
- [Tecnologias](#-tecnologias)
- [Arquitetura](#-arquitetura)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Quick Start](#-quick-start)
  - [Com Docker (Recomendado)](#com-docker-recomendado)
  - [Instala√ß√£o Manual](#instala√ß√£o-manual)
- [Docker - Guia Completo](#-docker---guia-completo)
- [API Documentation](#-api-documentation)
- [Testes](#-testes)
  - [Backend](#testes-backend)
  - [Frontend](#testes-frontend)
- [Deploy em Produ√ß√£o](#-deploy-em-produ√ß√£o)
- [Comandos √öteis](#-comandos-√∫teis)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)

---

## üéØ Sobre o Projeto

**DataDock** √© uma plataforma completa para importa√ß√£o, gerenciamento e consulta de grandes volumes de dados de m√∫ltiplas fontes. Desenvolvido com Django REST Framework no backend e Next.js no frontend, oferece uma interface moderna e APIs robustas para integra√ß√£o de dados empresariais.

### Por que DataDock?

- üöÄ **R√°pido**: Processamento otimizado com cache Redis e bulk operations
- üîí **Seguro**: Autentica√ß√£o JWT, permiss√µes granulares, rate limiting
- üìà **Escal√°vel**: Arquitetura preparada para grandes volumes
- üé® **Moderno**: Interface responsiva com Next.js 15 e shadcn/ui
- üê≥ **Deploy F√°cil**: Containerizado com Docker, pronto para produ√ß√£o
- üìä **Anal√≠tico**: Dashboard com m√©tricas e visualiza√ß√µes em tempo real

---

## ‚ú® Funcionalidades

### üì• Importa√ß√£o de Dados

- ‚úÖ Upload de arquivos CSV e Excel (.xlsx, .xls)
- ‚úÖ Importa√ß√£o de APIs externas (JSON)
- ‚úÖ Detec√ß√£o autom√°tica de tipos de dados
- ‚úÖ Valida√ß√£o e sanitiza√ß√£o de dados
- ‚úÖ Deduplica√ß√£o inteligente com hashing MD5
- ‚úÖ Processamento ass√≠ncrono com Celery (grandes volumes)
- ‚úÖ Preview de dados antes da importa√ß√£o
- ‚úÖ Limites configur√°veis (tamanho, linhas, colunas)

### üîç Consulta e Busca

- ‚úÖ Busca full-text em todos os datasets
- ‚úÖ Filtros avan√ßados por coluna (num√©ricos, texto, data, categoria)
- ‚úÖ Filtros de sele√ß√£o para colunas TEXT (at√© 100 valores √∫nicos)
- ‚úÖ Pagina√ß√£o otimizada
- ‚úÖ Export em CSV e Excel com filtros aplicados
- ‚úÖ Preview de dados
- ‚úÖ Metadados de colunas (tipos, valores √∫nicos, filter_type)
- ‚úÖ Datasets p√∫blicos e privados
- ‚úÖ Sele√ß√£o de colunas para download

### üìä Dashboard e Analytics

- ‚úÖ Estat√≠sticas agregadas em tempo real
- ‚úÖ Gr√°ficos de volume mensal
- ‚úÖ Status de datasets (ativos, arquivados)
- ‚úÖ Estimativa de armazenamento
- ‚úÖ Taxa de crescimento
- ‚úÖ Visualiza√ß√µes com Recharts

### üîê Seguran√ßa e Autentica√ß√£o

- ‚úÖ JWT Authentication com refresh tokens
- ‚úÖ Permiss√µes granulares (owner, admin, user)
- ‚úÖ Rate limiting por usu√°rio e IP
- ‚úÖ CORS configur√°vel
- ‚úÖ CSRF protection
- ‚úÖ Valida√ß√£o em m√∫ltiplas camadas
- ‚úÖ Logs de auditoria
- ‚úÖ Prote√ß√£o contra SQL injection, XSS, CSRF

### ‚ö° Performance

- ‚úÖ Cache Redis para queries frequentes
- ‚úÖ Bulk operations para inser√ß√µes
- ‚úÖ select_related/prefetch_related (Django ORM)
- ‚úÖ √çndices de banco otimizados
- ‚úÖ Streaming de downloads (mem√≥ria eficiente)
- ‚úÖ Lazy loading de dados
- ‚úÖ Gzip compression

### ü§ñ Alice AI Assistant (RAG)

- ‚úÖ Assistente virtual inteligente powered by Google Gemini
- ‚úÖ **RAG (Retrieval Augmented Generation)** com busca vetorial
- ‚úÖ Busca sem√¢ntica usando pgvector (PostgreSQL)
- ‚úÖ Embeddings com Google Gemini (models/embedding-001)
- ‚úÖ Auto-indexa√ß√£o de datasets com Django Signals
- ‚úÖ Respostas contextualizadas baseadas em dados reais
- ‚úÖ Top 5 datasets mais relevantes por pergunta
- ‚úÖ Comando de gerenciamento para indexar datasets existentes
- ‚úÖ Health check para verificar configura√ß√µes AI
- ‚úÖ **100% Gemini** - Sem depend√™ncia de OpenAI

---

## üõ†Ô∏è Tecnologias

### Backend

| Tecnologia | Vers√£o | Descri√ß√£o |
|------------|--------|-----------|
| Python | 3.12 | Linguagem principal |
| Django | 5.2 | Framework web |
| Django REST Framework | 3.16 | API REST |
| PostgreSQL | 16 | Banco de dados relacional |
| Redis | 7 | Cache e message broker |
| Celery | 5.4 | Processamento ass√≠ncrono |
| Gunicorn | 23.0 | WSGI server (produ√ß√£o) |
| Pandas | 2.2 | Processamento de dados |
| openpyxl | 3.1 | Manipula√ß√£o de Excel |
| **pgvector** | 0.3.6 | **Busca vetorial (RAG)** |
| **Google Gemini** | Latest | **Chat + Embeddings (100% Gemini)** |

### Frontend

| Tecnologia | Vers√£o | Descri√ß√£o |
|------------|--------|-----------|
| Next.js | 15.5 | Framework React |
| React | 19.1 | Biblioteca UI |
| TypeScript | 5 | Type safety |
| Tailwind CSS | 4 | Framework CSS |
| shadcn/ui | Latest | Componentes UI |
| Recharts | 3.2 | Biblioteca de gr√°ficos |
| Zod | 4.1 | Valida√ß√£o de schemas |
| React Hook Form | 7.65 | Gerenciamento de formul√°rios |
| Vitest | 2.1 | Framework de testes |

### DevOps e Infraestrutura

- **Docker** & **Docker Compose** - Containeriza√ß√£o
- **Nginx** - Proxy reverso e load balancer
- **GitHub** - Versionamento
- **Logging** - Logs estruturados e rotativos

---

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    NGINX (Porta 80/443)                          ‚îÇ
‚îÇ          Reverse Proxy + SSL + Static Files + Gzip              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                               ‚îÇ
              ‚îÇ                               ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ   Frontend      ‚îÇ            ‚îÇ    Backend      ‚îÇ
      ‚îÇ   Next.js 15    ‚îÇ            ‚îÇ   Django 5.2    ‚îÇ
      ‚îÇ   Port 3000     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Port 8000     ‚îÇ
      ‚îÇ                 ‚îÇ  REST API   ‚îÇ  + Gunicorn     ‚îÇ
      ‚îÇ  - React 19     ‚îÇ  JSON/JWT   ‚îÇ  - DRF          ‚îÇ
      ‚îÇ  - TypeScript   ‚îÇ             ‚îÇ  - Service Layer‚îÇ
      ‚îÇ  - Tailwind     ‚îÇ             ‚îÇ  - ORM          ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                         ‚îÇ                 ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Celery Worker  ‚îÇ    ‚îÇ   PostgreSQL   ‚îÇ  ‚îÇ     Redis       ‚îÇ
            ‚îÇ  Background     ‚îÇ    ‚îÇ   Database     ‚îÇ  ‚îÇ  Cache/Queue    ‚îÇ
            ‚îÇ  Tasks          ‚îÇ    ‚îÇ   Port 5432    ‚îÇ  ‚îÇ   Port 6379     ‚îÇ
            ‚îÇ  - Imports      ‚îÇ    ‚îÇ  - Dados       ‚îÇ  ‚îÇ  - Cache        ‚îÇ
            ‚îÇ  - Exports      ‚îÇ    ‚îÇ  - Users       ‚îÇ  ‚îÇ  - Sessions     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Celery Beat   ‚îÇ
            ‚îÇ  Scheduler     ‚îÇ
            ‚îÇ  - Cleanup     ‚îÇ
            ‚îÇ  - Reports     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Padr√µes de Design

- **Service Layer Pattern**: L√≥gica de neg√≥cio separada das views
- **Repository Pattern**: Abstra√ß√£o de acesso a dados (Django ORM)
- **Factory Pattern**: Cria√ß√£o de usu√°rios e processos
- **Dependency Injection**: Inje√ß√£o de depend√™ncias via Django
- **Clean Architecture**: Separa√ß√£o clara de responsabilidades

---

## üìÅ Estrutura do Projeto

### Estrutura Geral

```
dataport/
‚îú‚îÄ‚îÄ backend/                    # Django REST API
‚îú‚îÄ‚îÄ frontend/                   # Next.js Application
‚îú‚îÄ‚îÄ nginx/                      # Configura√ß√£o Nginx
‚îú‚îÄ‚îÄ docker-compose.yml          # Docker Compose
‚îî‚îÄ‚îÄ README.md                   # Documenta√ß√£o
```

### Backend (Django)

```
backend/
‚îú‚îÄ‚îÄ accounts/                   # Autentica√ß√£o e usu√°rios
‚îÇ   ‚îú‚îÄ‚îÄ management/commands/   # Comandos personalizados
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # User, Profile
‚îÇ   ‚îú‚îÄ‚îÄ serializers.py
‚îÇ   ‚îú‚îÄ‚îÄ services.py            # L√≥gica de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ views.py               # API Views
‚îÇ   ‚îî‚îÄ‚îÄ tests.py
‚îÇ
‚îú‚îÄ‚îÄ alice/                      # Assistente AI (RAG)
‚îÇ   ‚îú‚îÄ‚îÄ management/commands/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_service.py  # Busca vetorial
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # DatasetVector
‚îÇ   ‚îî‚îÄ‚îÄ views.py
‚îÇ
‚îú‚îÄ‚îÄ data_import/                # Importa√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # ImportProcess, DataTable
‚îÇ   ‚îú‚îÄ‚îÄ services.py
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py               # Celery tasks
‚îÇ   ‚îú‚îÄ‚îÄ views.py
‚îÇ   ‚îî‚îÄ‚îÄ cache.py               # Cache Redis
‚îÇ
‚îî‚îÄ‚îÄ core/                       # Settings Django
    ‚îú‚îÄ‚îÄ settings.py
    ‚îú‚îÄ‚îÄ urls.py
    ‚îú‚îÄ‚îÄ celery.py
    ‚îî‚îÄ‚îÄ health_checks.py
```

### Frontend (Next.js)

```
frontend/src/
‚îú‚îÄ‚îÄ app/                                # Next.js App Router
‚îÇ   ‚îú‚îÄ‚îÄ (auth)/                         # üîê Grupo de autentica√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ login/page.tsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ (private)/                      # üîí Rotas autenticadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/page.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [id]/page.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alice/page.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ajuda/page.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layout.tsx                  # Layout com sidebar
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ (public)/                       # üåê Rotas p√∫blicas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ home/page.tsx               # Landing page
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ datasets-publicos/page.tsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx                      # Layout raiz
‚îÇ   ‚îî‚îÄ‚îÄ page.tsx                        # Redirect inicial
‚îÇ
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ layout/                         # Componentes de layout
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sidebar/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app-sidebar.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ navigation/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ nav-main.tsx
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ nav-user.tsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ auth/                           # Autentica√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AuthGuard.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ LoginForm.tsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DatasetDialog.tsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ filters/                        # Filtros avan√ßados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ColumnFilterPopover.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ StringFilter.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NumberFilter.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DateFilter.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CategoryFilter.tsx
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ui/                             # shadcn/ui components
‚îÇ
‚îú‚îÄ‚îÄ hooks/                              # Custom hooks
‚îÇ   ‚îú‚îÄ‚îÄ useAuth.ts
‚îÇ   ‚îî‚îÄ‚îÄ useDatasets.ts
‚îÇ
‚îî‚îÄ‚îÄ lib/                                # Utilit√°rios
    ‚îú‚îÄ‚îÄ api.ts
    ‚îú‚îÄ‚îÄ auth.ts
    ‚îî‚îÄ‚îÄ config.ts
```

### Conven√ß√µes

**Rotas (App Router)**:
- `(auth)` - Grupo de autentica√ß√£o (login)
- `(private)` - Rotas protegidas (dashboard, datasets, alice)
- `(public)` - Rotas p√∫blicas (home, datasets p√∫blicos)
- `[id]` - Rotas din√¢micas

**Componentes**:
- `layout/` - Estrutura (sidebar, navigation, header)
- `auth/` - Autentica√ß√£o (AuthGuard, LoginForm)
- `datasets/` - Espec√≠ficos de datasets
- `filters/` - Componentes de filtro
- `ui/` - Componentes gen√©ricos (shadcn/ui)

---

## üöÄ Quick Start

### Com Docker (Recomendado)

**Pr√©-requisitos:** Docker 24.0+ e Docker Compose 2.20+

```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/seu-usuario/dataport.git
cd dataport

# 2. Configurar vari√°veis de ambiente
cp .env.example .env

# Editar .env e configurar:
# - POSTGRES_PASSWORD (senha do banco)
# - REDIS_PASSWORD (senha do Redis)
# - DJANGO_SECRET_KEY (chave secreta)
nano .env

# 3. Iniciar todos os servi√ßos
docker-compose up -d

# 4. Aguardar inicializa√ß√£o (30-60 segundos)
docker-compose logs -f

# 5. Criar superusu√°rio (primeiro acesso)
docker-compose exec backend python manage.py createsuperuser
```

**Pronto!** üéâ Acesse:
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **Admin Django**: http://localhost:8000/admin
- **API Docs**: http://localhost:8000/api/docs

### Instala√ß√£o Manual

#### Pr√©-requisitos

- **Python 3.12+** ([Download](https://www.python.org/downloads/))
- **Node.js 20+** ([Download](https://nodejs.org/))
- **Git** ([Download](https://git-scm.com/))
- **Google Gemini API Key** (Opcional - para Alice AI) - [Obter aqui](https://ai.google.dev/)

---

#### üì¶ Passo 1: Clonar o Reposit√≥rio

```bash
git clone https://github.com/seu-usuario/dataport.git
cd dataport
```

---

#### üêç Passo 2: Configurar Backend (Django)

```bash
# 1. Navegar para pasta backend
cd backend

# 2. Criar ambiente virtual
python -m venv venv

# 3. Ativar ambiente virtual
# Windows (CMD):
venv\Scripts\activate

# Windows (PowerShell):
venv\Scripts\Activate.ps1

# Linux/Mac:
source venv/bin/activate

# 4. Atualizar pip
python -m pip install --upgrade pip

# 5. Instalar depend√™ncias
pip install -r requirements.txt

# 6. Criar arquivo .env
# Windows:
copy .env.example .env

# Linux/Mac:
cp .env.example .env

# 7. Editar .env e configurar as vari√°veis
# Abra o arquivo .env em um editor de texto e configure:
```

**Exemplo de `.env` m√≠nimo:**
```bash
# Django
DJANGO_SECRET_KEY=sua-chave-secreta-aqui-gere-uma-nova
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1

# Database (SQLite - padr√£o)
# Nenhuma configura√ß√£o necess√°ria, criado automaticamente

# Redis (Opcional - fallback para cache em mem√≥ria se n√£o dispon√≠vel)
REDIS_URL=redis://localhost:6379/0

# Google Gemini AI (Opcional - para assistente Alice)
GEMINI_API_KEY=your-gemini-api-key-here

# Frontend URL
FRONTEND_URL=http://localhost:3000
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Celery (Opcional)
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/1
```

**üí° Dica:** Para gerar uma chave secreta segura:
```bash
python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())"
```

```bash
# 8. Executar migra√ß√µes do banco de dados
python manage.py migrate

# 9. Criar superusu√°rio (admin)
python manage.py createsuperuser
# Siga as instru√ß√µes interativas

# 10. (Opcional) Criar dados de exemplo
python manage.py create_sample_data

# 11. Iniciar servidor Django
python manage.py runserver
```

**‚úÖ Backend rodando em:** `http://localhost:8000`

---

#### ‚öõÔ∏è Passo 3: Configurar Frontend (Next.js)

**Abra um NOVO terminal** (deixe o backend rodando no anterior)

```bash
# 1. Navegar para pasta frontend (a partir da raiz do projeto)
cd frontend

# 2. Instalar depend√™ncias
npm install

# 3. Criar arquivo .env.local
# Windows:
copy .env.example .env.local

# Linux/Mac:
cp .env.example .env.local

# 4. Editar .env.local
# Abra o arquivo e verifique se est√° assim:
```

**`.env.local`:**
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

```bash
# 5. Iniciar servidor Next.js
npm run dev
```

**‚úÖ Frontend rodando em:** `http://localhost:3000`

---

#### üéâ Passo 4: Acessar o Sistema

Ap√≥s seguir todos os passos acima, voc√™ ter√°:

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Frontend (App)** | http://localhost:3000 | Use o usu√°rio criado no passo 9 |
| **Backend API** | http://localhost:8000 | - |
| **Admin Django** | http://localhost:8000/admin | Use o superusu√°rio criado |
| **API Docs (Swagger)** | http://localhost:8000/api/docs | - |
| **API Schema** | http://localhost:8000/api/schema | - |

---

#### üîß Passo 5: Servi√ßos Opcionais

##### Redis (Recomendado para produ√ß√£o)

**Op√ß√£o 1 - Docker (mais f√°cil):**
```bash
docker run -d -p 6379:6379 --name redis-dataport redis:7-alpine
```

**Op√ß√£o 2 - Instala√ß√£o local:**
- **Windows**: [Redis for Windows](https://github.com/microsoftarchive/redis/releases)
- **Linux**: `sudo apt install redis-server && sudo systemctl start redis`
- **Mac**: `brew install redis && brew services start redis`

##### Celery Workers (Para processamento ass√≠ncrono)

**Terminal 3:**
```bash
cd backend
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

celery -A core worker -l info --pool=solo  # Windows
# celery -A core worker -l info  # Linux/Mac
```

**Terminal 4 (Scheduler - opcional):**
```bash
cd backend
venv\Scripts\activate  # Windows

celery -A core beat -l info
```

---

#### üìù Resumo dos Comandos para Pr√≥ximas Execu√ß√µes

Depois da instala√ß√£o inicial, para subir o sistema:

**Terminal 1 - Backend:**
```bash
cd backend
venv\Scripts\activate  # Windows
python manage.py runserver
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

**Terminal 3 - Celery (Opcional):**
```bash
cd backend
venv\Scripts\activate  # Windows
celery -A core worker -l info --pool=solo
```

---

## üê≥ Docker - Guia Completo

üìñ **[Documenta√ß√£o Completa de Docker](DOCKER.md)** - Guia detalhado com comandos, troubleshooting e dicas

### Estrutura de Servi√ßos

```yaml
services:
  postgres    # Banco de dados PostgreSQL 16
  redis       # Cache e message broker
  backend     # Django + Gunicorn
  celery-worker  # Background tasks
  celery-beat    # Scheduler
  frontend    # Next.js
  nginx       # Proxy reverso (opcional)
```

### Comandos Docker

#### Desenvolvimento

```bash
# Modo desenvolvimento (hot reload)
docker-compose -f docker-compose.dev.yml up -d

# Ver logs em tempo real
docker-compose -f docker-compose.dev.yml logs -f

# Ver logs de um servi√ßo espec√≠fico
docker-compose -f docker-compose.dev.yml logs -f backend

# Parar servi√ßos
docker-compose -f docker-compose.dev.yml down
```

#### Produ√ß√£o

```bash
# Build das imagens
docker-compose build

# Build sem cache (rebuild completo)
docker-compose build --no-cache

# Iniciar em background
docker-compose up -d

# Ver status dos containers
docker-compose ps

# Parar servi√ßos
docker-compose down

# Parar e remover volumes (CUIDADO: apaga dados!)
docker-compose down -v
```

#### Gerenciamento

```bash
# Executar comandos Django
docker-compose exec backend python manage.py migrate
docker-compose exec backend python manage.py createsuperuser
docker-compose exec backend python manage.py collectstatic

# Acessar shell do container
docker-compose exec backend bash
docker-compose exec frontend sh

# Reiniciar um servi√ßo espec√≠fico
docker-compose restart backend

# Ver uso de recursos
docker stats

# Ver logs
docker-compose logs --tail=100 backend
docker-compose logs --since 2024-01-01T10:00:00
```

#### Banco de Dados

```bash
# Backup do banco
docker-compose exec postgres pg_dump -U dataport dataport > backup_$(date +%Y%m%d).sql

# Restaurar backup
docker-compose exec -T postgres psql -U dataport dataport < backup.sql

# Acessar PostgreSQL
docker-compose exec postgres psql -U dataport -d dataport

# Ver tabelas
docker-compose exec postgres psql -U dataport -d dataport -c "\dt"
```

#### Limpeza

```bash
# Remover containers parados
docker container prune

# Remover imagens n√£o utilizadas
docker image prune -a

# Remover volumes n√£o utilizados
docker volume prune

# Limpeza completa (CUIDADO!)
docker system prune -a --volumes
```

### Vari√°veis de Ambiente (.env)

```bash
# PostgreSQL
POSTGRES_DB=dataport
POSTGRES_USER=dataport
POSTGRES_PASSWORD=sua_senha_segura_aqui

# Redis
REDIS_PASSWORD=sua_senha_redis_aqui

# Django
DJANGO_SECRET_KEY=sua_chave_secreta_muito_longa_aqui
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1,seu-dominio.com

# CORS
CORS_ALLOWED_ORIGINS=http://localhost:3000,https://seu-dominio.com

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000

# Email (opcional)
EMAIL_BACKEND=django.core.mail.backends.smtp.EmailBackend
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_USE_TLS=True
EMAIL_HOST_USER=seu-email@gmail.com
EMAIL_HOST_PASSWORD=sua-senha-de-app
```

### Health Checks

Todos os servi√ßos t√™m health checks autom√°ticos. Endpoints dispon√≠veis:

| Endpoint | Descri√ß√£o | Componentes Verificados |
|----------|-----------|------------------------|
| `/health/` | Basic health check | Database |
| `/health/detailed/` | Verifica√ß√£o completa | Database, Redis, Celery, Disk Space |
| `/health/ready/` | Readiness probe (Kubernetes) | Database |
| `/health/live/` | Liveness probe (Kubernetes) | Application status |

```bash
# Verificar sa√∫de dos servi√ßos
docker-compose ps

# Testar endpoints
curl http://localhost:8000/health/
curl http://localhost:8000/health/detailed/
curl http://localhost:8000/health/ready/
curl http://localhost:8000/health/live/

# Resposta de exemplo (health/detailed/)
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "checks": {
    "database": {"status": "healthy", "message": "Database connection OK"},
    "cache": {"status": "healthy", "message": "Cache connection OK"},
    "celery": {"status": "healthy", "message": "2 Celery worker(s) active"},
    "disk": {"status": "healthy", "used_percent": 45.2, "free_gb": 120.5}
  }
}
```

### Volumes Persistentes

```yaml
volumes:
  postgres_data:     # Dados do PostgreSQL
  redis_data:        # Dados do Redis
  backend_logs:      # Logs do backend
  backend_static:    # Arquivos est√°ticos
  backend_media:     # Uploads de usu√°rios
  nginx_logs:        # Logs do Nginx
```

**IMPORTANTE:** Fazer backup regular dos volumes!

---

## üìö API Documentation

### Documenta√ß√£o Interativa

- **Swagger UI**: http://localhost:8000/api/docs/
- **ReDoc**: http://localhost:8000/api/redoc/
- **OpenAPI Schema**: http://localhost:8000/api/schema/

### Endpoints Principais

#### Autentica√ß√£o

```bash
# Login
POST /api/auth/login
Body: {"email": "user@example.com", "password": "senha"}
Response: {"access": "token...", "refresh": "token...", "user": {...}}

# Refresh Token
POST /api/auth/refresh
Body: {"refresh": "refresh_token..."}
Response: {"access": "novo_access_token..."}

# Logout
POST /api/auth/logout
Headers: Authorization: Bearer {token}
Body: {"refresh": "refresh_token..."}
```

#### Importa√ß√£o de Dados

```bash
# Criar importa√ß√£o (arquivo)
POST /api/data-import/
Headers: Authorization: Bearer {token}
Body (multipart/form-data):
  - file: arquivo.csv
  - table_name: "vendas_2024"
  - import_type: "file"

# Criar importa√ß√£o (API)
POST /api/data-import/
Headers: Authorization: Bearer {token}
Body (JSON):
{
  "table_name": "usuarios_api",
  "endpoint_url": "https://api.example.com/users",
  "import_type": "endpoint"
}

# Listar processos
GET /api/data-import/processes/?page=1&page_size=20
Headers: Authorization: Bearer {token}

# Detalhes do processo
GET /api/data-import/processes/{id}/
Headers: Authorization: Bearer {token}

# Preview dos dados
GET /api/data-import/processes/{id}/preview/
Headers: Authorization: Bearer {token}
Response: {"columns": [...], "data": [...], "total_records": 1000}

# Download
GET /api/data-import/processes/{id}/download/
Headers: Authorization: Bearer {token}
Response: arquivo CSV

# Adicionar mais dados
POST /api/data-import/processes/{id}/append/
Headers: Authorization: Bearer {token}
Body: (mesmo formato do POST /api/data-import/)

# Deletar processo
DELETE /api/data-import/processes/{id}/delete/
Headers: Authorization: Bearer {token}

# Alternar status (ativo/inativo)
POST /api/data-import/processes/{id}/toggle-status/
Headers: Authorization: Bearer {token}
```

#### Busca e Consulta

```bash
# Buscar em todos os datasets
GET /api/data-import/search/?q=termo_busca
Headers: Authorization: Bearer {token}
Response: {"results": [...], "total_tables": 5}

# Busca p√∫blica (sem auth)
GET /api/data-import/public-search/?q=termo
Response: {"results": [...]}

# Listar datasets p√∫blicos
GET /api/data-import/public-datasets/
Response: {"count": 10, "results": [...]}

# Dados p√∫blicos de um dataset
GET /api/data-import/public-data/{id}/
Response: {"columns": [...], "data": [...]}

# Metadados de colunas (com tipos de filtros)
GET /api/data-import/public-metadata/{id}/
Response: {
  "columns": [
    {
      "name": "nome",
      "type": "TEXT",
      "filter_type": "category",  # string, integer, float, date, category
      "unique_values": ["valor1", "valor2", ...]  # at√© 100 valores
    }
  ]
}
```

#### Analytics

```bash
# Estat√≠sticas do dashboard
GET /api/data-import/dashboard-stats/
Headers: Authorization: Bearer {token}
Response: {
  "metrics": {
    "total_datasets": 45,
    "active_datasets": 32,
    "total_records": 1250000,
    "storage_tb": 2.5,
    "growth_rate": 15.3
  },
  "dataset_status": [...],
  "monthly_volume": [...]
}
```

#### Exemplos com cURL

```bash
# 1. Login
TOKEN=$(curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@dataport.com","password":"admin123"}' \
  | jq -r '.access')

# 2. Upload de arquivo
curl -X POST http://localhost:8000/api/data-import/ \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@dados.csv" \
  -F "table_name=vendas_jan" \
  -F "import_type=file"

# 3. Importar de API
curl -X POST http://localhost:8000/api/data-import/ \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "table_name": "usuarios_github",
    "endpoint_url": "https://api.github.com/users",
    "import_type": "endpoint"
  }'

# 4. Listar datasets
curl http://localhost:8000/api/data-import/processes/ \
  -H "Authorization: Bearer $TOKEN"

# 5. Buscar dados
curl "http://localhost:8000/api/data-import/search/?q=brasil" \
  -H "Authorization: Bearer $TOKEN"

# 6. Download
curl http://localhost:8000/api/data-import/processes/1/download/ \
  -H "Authorization: Bearer $TOKEN" \
  -o dados.csv
```

---

## ü§ñ Alice AI Assistant com RAG

Alice √© a assistente virtual inteligente do DataDock, powered by **Google Gemini** com **RAG (Retrieval Augmented Generation)** para busca sem√¢ntica.

### üéØ O que √© RAG?

RAG combina:
- **Busca Vetorial**: Encontra datasets semanticamente similares √† pergunta
- **LLM (Gemini)**: Gera respostas naturais baseadas nos dados encontrados
- **Contextualiza√ß√£o**: Respostas precisas usando dados reais do sistema

### üîß Configura√ß√£o

#### 1. Instalar depend√™ncias

```bash
cd backend
pip install pgvector==0.3.6
```

#### 2. Configurar vari√°veis de ambiente

Adicione ao `.env`:

```bash
# Google Gemini API Key (usado para chat E embeddings)
GEMINI_API_KEY=sua-chave-gemini-aqui
```

**Como obter a chave:**
- **Gemini API Key**: https://makersuite.google.com/app/apikey (GR√ÅTIS)

#### 3. Aplicar migra√ß√µes

```bash
python manage.py migrate alice
```

Isso habilita a extens√£o `pgvector` no PostgreSQL.

#### 4. Indexar datasets existentes

```bash
# Indexar todos os datasets completos
python manage.py index_datasets

# Reindexar tudo (incluindo j√° indexados)
python manage.py index_datasets --all

# Indexar dataset espec√≠fico por ID
python manage.py index_datasets --dataset-id 123

# Indexar dataset espec√≠fico por nome
python manage.py index_datasets --table-name data001
```

### üìä Como funciona

1. **Pergunta do usu√°rio**: "Quais dados de importa√ß√£o temos?"
2. **Embedding da pergunta**: Gemini gera vetor de 768 dimens√µes (models/embedding-001)
3. **Busca vetorial**: pgvector encontra top 5 datasets similares via L2Distance
4. **Contexto enriquecido**: Monta contexto com datasets relevantes
5. **Resposta AI**: Gemini gera resposta natural baseada no contexto

### üîç Endpoints

#### Chat com Alice

```bash
POST /api/alice/chat/
Content-Type: application/json
Authorization: Bearer <token>

{
  "message": "Quais datasets de navega√ß√£o temos dispon√≠veis?"
}
```

**Resposta:**

```json
{
  "success": true,
  "response": "Encontrei **3 datasets** de navega√ß√£o:\n\n1. **data_navegacao_2024** - 15.234 registros\n2. **shipping_logs** - 8.901 registros\n3. **vessel_tracking** - 23.456 registros\n\nTodos cont√™m dados atualizados de movimenta√ß√£o portu√°ria.",
  "timestamp": "2025-12-28T10:30:00Z"
}
```

#### Health Check

```bash
GET /api/alice/health/
Authorization: Bearer <token>
```

**Resposta:**

```json
{
  "status": "healthy",
  "service": "Alice AI Assistant",
  "gemini_configured": true,
  "rag_enabled": true,
  "embedding_model": "Google Gemini models/embedding-001",
  "timestamp": "2025-12-28T10:30:00Z"
}
```

### üöÄ Indexa√ß√£o Autom√°tica

Datasets s√£o **automaticamente indexados** quando:
- ‚úÖ Status muda para `completed`
- ‚úÖ Dataset √© criado via upload/API
- ‚úÖ Dataset √© atualizado

Implementado via **Django Signals** em `alice/signals.py`.

### üìÅ Arquitetura

```
alice/
‚îú‚îÄ‚îÄ models.py              # DatasetEmbedding model (VectorField)
‚îú‚îÄ‚îÄ views.py               # AliceChatView com RAG
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ vector_service.py  # VectorService (embeddings, busca)
‚îú‚îÄ‚îÄ signals.py             # Auto-indexa√ß√£o
‚îú‚îÄ‚îÄ migrations/
‚îÇ   ‚îî‚îÄ‚îÄ 0001_enable_vector_extension.py
‚îî‚îÄ‚îÄ management/
    ‚îî‚îÄ‚îÄ commands/
        ‚îî‚îÄ‚îÄ index_datasets.py  # Comando de indexa√ß√£o
```

### üé® Modelo de Embedding

```python
class DatasetEmbedding(models.Model):
    dataset = OneToOneField('DataImportProcess')  # Rela√ß√£o 1:1
    description = TextField()                     # Descri√ß√£o textual
    embedding = VectorField(dimensions=768)       # Vetor Gemini
    metadata = JSONField()                        # Metadados adicionais
    created_at = DateTimeField(auto_now_add=True)
    updated_at = DateTimeField(auto_now=True)
```

### üí° Dicas

- **Custo**: Gemini Embeddings s√£o **GRATUITOS** (at√© 1500 requisi√ß√µes/dia)
- **Performance**: Busca vetorial √© extremamente r√°pida (ms)
- **Precis√£o**: RAG retorna apenas datasets relevantes
- **Fallback**: Se RAG falhar, usa contexto tradicional
- **100% Gemini**: Uma √∫nica API key para tudo (chat + embeddings)

### üîí Rate Limiting

- **30 requisi√ß√µes/minuto** por usu√°rio
- Retry autom√°tico com exponential backoff
- Cache de contexto (5 minutos)

---

## üß™ Testes

### Testes Backend

#### Executar Testes

```bash
cd backend

# Todos os testes
python manage.py test

# App espec√≠fico
python manage.py test accounts
python manage.py test data_import

# Teste espec√≠fico
python manage.py test accounts.tests.UserSerializerTest

# Com verbose
python manage.py test --verbosity=2

# Manter banco de testes (mais r√°pido)
python manage.py test --keepdb
```

#### Cobertura de Testes

```bash
# Instalar coverage
pip install coverage

# Executar com cobertura
coverage run --source='.' manage.py test

# Ver relat√≥rio
coverage report

# Gerar HTML
coverage html
# Abrir htmlcov/index.html no navegador

# Ver apenas arquivos com menos de 80%
coverage report --skip-covered --skip-empty
```

#### Testes Existentes (Backend)

**accounts app** (~450 linhas de testes):
- ‚úÖ Models (Company, CustomUser, Profiles)
- ‚úÖ Serializers (UserSerializer)
- ‚úÖ Views (Login, Password Reset, Change Password)
- ‚úÖ APIs (Company, User management)
- **Cobertura**: ~80%

**data_import app**:
- ‚ö†Ô∏è **Em desenvolvimento** (0% cobertura)
- Necess√°rio: testes de importa√ß√£o, valida√ß√£o, servi√ßos

### Testes Frontend

#### Configura√ß√£o

Framework de testes configurado:
- **Vitest** - Framework de testes r√°pido
- **React Testing Library** - Testes de componentes
- **@testing-library/jest-dom** - Matchers customizados
- **jsdom** - Ambiente DOM

#### Executar Testes

```bash
cd frontend

# Todos os testes
npm test

# Watch mode (reexecuta ao salvar)
npm test -- --watch

# Interface visual
npm run test:ui

# Cobertura
npm run test:coverage

# Teste espec√≠fico
npm test auth.test.ts

# Com UI e cobertura
npm run test:ui -- --coverage
```

#### Testes Existentes (Frontend)

**lib/auth.test.ts** (10 testes):
- ‚úÖ getAccessToken / getRefreshToken
- ‚úÖ setAuthTokens
- ‚úÖ clearAuthData
- ‚úÖ isAuthenticated
- ‚úÖ getTokenExpiration
- ‚úÖ isTokenExpired (com buffer)

**lib/api.test.ts** (6 testes):
- ‚úÖ apiGet com autentica√ß√£o
- ‚úÖ apiPost com dados
- ‚úÖ apiDelete
- ‚úÖ Tratamento de erro 401
- ‚úÖ Refresh autom√°tico de token

**hooks/useAuth.test.tsx** (3 testes):
- ‚úÖ Estado inicial
- ‚úÖ Usu√°rio n√£o autenticado
- ‚úÖ Usu√°rio autenticado

**Total**: 19 testes | **Cobertura**: ~30%

#### Estrutura de Testes

```
frontend/src/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ __tests__/
‚îÇ       ‚îú‚îÄ‚îÄ auth.test.ts
‚îÇ       ‚îî‚îÄ‚îÄ api.test.ts
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ __tests__/
‚îÇ       ‚îî‚îÄ‚îÄ useAuth.test.tsx
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ setup.ts          # Configura√ß√£o global
```

#### Exemplo de Teste

```typescript
// lib/__tests__/auth.test.ts
import { describe, it, expect, beforeEach } from 'vitest'
import { getAccessToken, setAuthTokens } from '../auth'

describe('Auth Utils', () => {
  beforeEach(() => {
    localStorage.clear()
  })

  it('deve armazenar access token', () => {
    setAuthTokens({ access: 'test-token' })
    expect(getAccessToken()).toBe('test-token')
  })

  it('deve retornar null quando n√£o h√° token', () => {
    expect(getAccessToken()).toBeNull()
  })
})
```

---

## üö¢ Deploy em Produ√ß√£o

### Checklist Pr√©-Deploy

- [ ] Configurar vari√°veis de ambiente
- [ ] Alterar `DJANGO_SECRET_KEY`
- [ ] Configurar senhas seguras (PostgreSQL, Redis)
- [ ] `DEBUG=False`
- [ ] Configurar `ALLOWED_HOSTS`
- [ ] Configurar `CORS_ALLOWED_ORIGINS`
- [ ] Configurar dom√≠nio e SSL/HTTPS
- [ ] Testar build localmente
- [ ] Configurar backup autom√°tico
- [ ] Configurar monitoramento (opcional)

### Deploy com Docker

```bash
# 1. Configurar produ√ß√£o
cp .env.example .env
# Editar .env com valores de produ√ß√£o

# 2. Build
docker-compose build

# 3. Iniciar
docker-compose up -d

# 4. Verificar
docker-compose ps
docker-compose logs -f

# 5. Criar superuser
docker-compose exec backend python manage.py createsuperuser

# 6. Collectstatic (se n√£o autom√°tico)
docker-compose exec backend python manage.py collectstatic --noinput
```

### SSL/HTTPS com Nginx

```bash
# 1. Instalar Certbot
docker-compose exec nginx apk add certbot

# 2. Obter certificado
docker-compose exec nginx certbot --nginx -d seu-dominio.com

# 3. Renova√ß√£o autom√°tica (cron)
0 0 * * * docker-compose exec nginx certbot renew --quiet
```

### Backup Autom√°tico

```bash
# Script de backup (backup.sh)
#!/bin/bash
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)

# Backup PostgreSQL
docker-compose exec -T postgres pg_dump -U dataport dataport > \
  ${BACKUP_DIR}/db_backup_${DATE}.sql

# Backup volumes
docker run --rm -v dataport-backend-media:/data -v ${BACKUP_DIR}:/backup \
  alpine tar czf /backup/media_${DATE}.tar.gz -C /data .

# Manter apenas √∫ltimos 7 dias
find ${BACKUP_DIR} -name "*.sql" -mtime +7 -delete
find ${BACKUP_DIR} -name "*.tar.gz" -mtime +7 -delete
```

Agendar no cron:
```bash
0 2 * * * /path/to/backup.sh
```

### Monitoramento (Opcional)

#### Health Checks

```bash
# Adicionar ao cron
*/5 * * * * curl -f http://seu-dominio.com/health/ || echo "Site down" | mail -s "Alert" admin@example.com
```

#### Logs Centralizados

```bash
# docker-compose.yml
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

---

## üõ†Ô∏è Comandos √öteis

### Django

```bash
# Migra√ß√µes
python manage.py makemigrations
python manage.py migrate
python manage.py showmigrations

# Superuser
python manage.py createsuperuser

# Shell
python manage.py shell
python manage.py dbshell

# Limpar sess√µes expiradas
python manage.py clearsessions

# Coletar arquivos est√°ticos
python manage.py collectstatic

# Comandos customizados
python manage.py create_sample_data
python manage.py create_user_with_profile
```

### Next.js

```bash
# Desenvolvimento
npm run dev

# Build
npm run build

# Produ√ß√£o
npm start

# Lint
npm run lint

# Testes
npm test
npm run test:coverage
```

### Git

```bash
# Status
git status

# Commit (Conventional Commits)
git commit -m "feat: adicionar importa√ß√£o de Excel"
git commit -m "fix: corrigir bug de autentica√ß√£o"
git commit -m "docs: atualizar README"

# Push
git push origin main

# Pull
git pull origin main
```

### PostgreSQL

```bash
# Conectar
psql -U dataport -d dataport

# Comandos √∫teis
\dt                 # Listar tabelas
\d+ table_name      # Descrever tabela
\l                  # Listar databases
\du                 # Listar usu√°rios
\q                  # Sair

# Queries √∫teis
SELECT COUNT(*) FROM data_import_importeddatarecord;
SELECT table_name, record_count FROM data_import_dataimportprocess;
```

---

## üîß Troubleshooting

### Problema: Containers n√£o iniciam

```bash
# Ver logs detalhados
docker-compose logs

# Verificar portas em uso
netstat -tulpn | grep -E ':(3000|8000|5432|6379|80)'

# Rebuild for√ßado
docker-compose down -v
docker-compose build --no-cache
docker-compose up
```

### Problema: Erro de conex√£o com banco

```bash
# Verificar se PostgreSQL est√° healthy
docker-compose ps postgres

# Ver logs
docker-compose logs postgres

# Testar conex√£o
docker-compose exec backend python manage.py dbshell
```

### Problema: Frontend n√£o conecta ao backend

1. Verificar `NEXT_PUBLIC_API_URL` no `.env.local`
2. Verificar `CORS_ALLOWED_ORIGINS` no backend
3. Testar backend: `curl http://localhost:8000/health/`
4. Ver logs: `docker-compose logs backend`

### Problema: Celery n√£o processa tasks

```bash
# Ver logs do worker
docker-compose logs celery-worker

# Verificar conex√£o com Redis
docker-compose exec backend python -c "import redis; r = redis.Redis(host='redis', port=6379); print(r.ping())"

# Listar tasks registradas
docker-compose exec celery-worker celery -A core inspect registered
```

### Problema: Erro 401 Unauthorized

1. Verificar se token est√° sendo enviado: `Authorization: Bearer {token}`
2. Verificar se token n√£o expirou (60 minutos)
3. Fazer refresh do token: `POST /api/auth/refresh`
4. Ver logs: `docker-compose logs backend`

### Problema: Importa√ß√£o falha

```bash
# Ver logs detalhados
docker-compose logs backend | grep -i error

# Verificar limites
# MAX_ROWS = 100000
# MAX_COLUMNS = 100
# MAX_FILE_SIZE = 50MB

# Testar manualmente
docker-compose exec backend python manage.py shell
>>> from data_import.services import DataImportService
>>> DataImportService.process_file_data(file)
```

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o muito bem-vindas! Siga os passos:

### 1. Fork e Clone

```bash
# Fork no GitHub
# Clonar seu fork
git clone https://github.com/seu-usuario/dataport.git
cd dataport
```

### 2. Criar Branch

```bash
git checkout -b feature/minha-feature
# ou
git checkout -b fix/meu-bugfix
```

### 3. Desenvolver

- Escrever c√≥digo limpo e documentado
- Seguir padr√µes de c√≥digo (PEP 8, ESLint)
- Adicionar testes
- Testar localmente

```bash
# Backend
cd backend
python manage.py test

# Frontend
cd frontend
npm test
```

### 4. Commit

Use **Conventional Commits**:

```bash
# Formato
tipo(escopo): descri√ß√£o curta

# Exemplos
git commit -m "feat: adicionar importa√ß√£o de JSON"
git commit -m "fix: corrigir valida√ß√£o de email"
git commit -m "docs: atualizar guia de instala√ß√£o"
git commit -m "style: formatar c√≥digo com black"
git commit -m "refactor: extrair l√≥gica para service layer"
git commit -m "test: adicionar testes para auth"
git commit -m "chore: atualizar depend√™ncias"
```

**Tipos**:
- `feat`: Nova funcionalidade
- `fix`: Corre√ß√£o de bug
- `docs`: Documenta√ß√£o
- `style`: Formata√ß√£o de c√≥digo
- `refactor`: Refatora√ß√£o
- `test`: Testes
- `chore`: Manuten√ß√£o

### 5. Push e Pull Request

```bash
git push origin feature/minha-feature
```

Abra Pull Request no GitHub com:
- T√≠tulo descritivo
- Descri√ß√£o do que foi feito
- Screenshots (se aplic√°vel)
- Refer√™ncia a issues

### Code Style

**Backend (Python)**:
- PEP 8
- Black formatter
- Type hints
- Docstrings

**Frontend (TypeScript)**:
- ESLint
- Prettier
- Tipos expl√≠citos
- JSDoc quando necess√°rio

### Revis√£o

Seu PR ser√° revisado. Mudan√ßas podem ser solicitadas.

---

## üìä Status do Projeto

### Qualidade de C√≥digo

| Categoria | Nota | Status |
|-----------|------|--------|
| Arquitetura | 8.0/10 | ‚úÖ Excelente |
| Backend | 7.5/10 | ‚úÖ Bom |
| Frontend | 6.5/10 | ‚ö†Ô∏è Precisa melhorias |
| API Design | 8.0/10 | ‚úÖ Excelente |
| Seguran√ßa | 7.0/10 | ‚úÖ Bom |
| Testes | 5.5/10 | ‚ö†Ô∏è Em desenvolvimento |
| Documenta√ß√£o | 9.0/10 | ‚úÖ Excelente |

**M√©dia Geral**: 7.4/10

### Cobertura de Testes

- **Backend accounts**: ~80% ‚úÖ
- **Backend data_import**: 0% ‚ö†Ô∏è (em desenvolvimento)
- **Frontend**: ~30% ‚ö†Ô∏è (em desenvolvimento)

### Melhorias Recentes (v1.0.6)

- ‚úÖ Reorganiza√ß√£o completa da estrutura do frontend
  - Grupos de rotas: `(auth)`, `(private)`, `(public)`
  - Componentes organizados em: `layout/`, `auth/`, `datasets/`, `filters/`
  - Documenta√ß√£o completa da estrutura no README
- ‚úÖ Corre√ß√£o de bug cr√≠tico: Timestamp serialization (datasets com colunas de data)
- ‚úÖ Filtros de categoria para colunas TEXT (sele√ß√£o de valores √∫nicos)
- ‚úÖ Favicon/√≠cone do site (database icon azul)
- ‚úÖ Docker otimizado com multi-stage builds
- ‚úÖ Configura√ß√£o Nginx completa (proxy reverso, cache, gzip)
- ‚úÖ Limpeza de c√≥digo e coment√°rios em PT-BR
- ‚úÖ Documenta√ß√£o Docker completa (DOCKER.md)
- ‚úÖ Health checks robustos (basic, detailed, ready, live)
- ‚úÖ Next.js standalone output para Docker

### Roadmap

#### v1.1 (Em desenvolvimento)

- [ ] Testes completos para data_import
- [ ] Cobertura de testes frontend >70%
- [ ] CI/CD com GitHub Actions
- [ ] Modo escuro completo
- [ ] PWA (Progressive Web App)

#### v2.0 (Planejado)

- [ ] OAuth2 (Google, GitHub, Microsoft)
- [ ] 2FA (Autentica√ß√£o de dois fatores)
- [ ] GraphQL API
- [ ] WebSockets (real-time updates)
- [ ] Export para Parquet, JSON
- [ ] Visualiza√ß√µes D3.js
- [ ] ML para an√°lise de dados
- [ ] S3 storage integration
- [ ] Multi-tenancy
- [ ] Internacionaliza√ß√£o (i18n)

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

```
MIT License

Copyright (c) 2024 DataDock

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## üë• Autores

- **Seu Nome** - *Desenvolvimento inicial* - [GitHub](https://github.com/seu-usuario)

Veja tamb√©m a lista de [contribuidores](https://github.com/seu-usuario/dataport/contributors).

---

## üôè Agradecimentos

- [Django](https://www.djangoproject.com/) - Framework web Python
- [Next.js](https://nextjs.org/) - Framework React
- [shadcn/ui](https://ui.shadcn.com/) - Componentes UI
- [Tailwind CSS](https://tailwindcss.com/) - Framework CSS
- [PostgreSQL](https://www.postgresql.org/) - Banco de dados
- [Redis](https://redis.io/) - Cache e message broker
- Comunidade open source ‚ù§Ô∏è

---

## üìû Suporte

- **Documenta√ß√£o**: [Wiki](https://github.com/seu-usuario/dataport/wiki)
- **Docker Guide**: [DOCKER.md](DOCKER.md) - Guia completo de Docker
- **Issues**: [GitHub Issues](https://github.com/seu-usuario/dataport/issues)
- **Discuss√µes**: [GitHub Discussions](https://github.com/seu-usuario/dataport/discussions)

---

<div align="center">

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela! ‚≠ê**

**Desenvolvido com ‚ù§Ô∏è para facilitar a gest√£o de dados**

[‚¨Ü Voltar ao topo](#-datadock)

</div>
